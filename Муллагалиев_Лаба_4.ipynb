{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled18.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a60TApNUQP-"
      },
      "source": [
        "Домашняя раюота"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i70e2ECBUS82"
      },
      "source": [
        "Задание 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkexSuTJUUue"
      },
      "source": [
        "Реализуйте класс LinearRegressionSGD c обучением и и применением линейной регрессии, построенной с помощью стохастического градиентного спуска, с заданным интерфейсом.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0t5n_MuUaWS"
      },
      "source": [
        "Обратите внимание на следуюшие моменты:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Выход из цикла осуществуется по сравнению 2-нормы разницы весов с epsilon, а функция потерь - MSE.\n",
        "\n",
        "1.   Схожий класс использовался в лекции\n",
        "2.   Выбирайте 10 случайных сэмплов (равномерно) каждый раз.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Визуализируйте траекторию градиентного спуска:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLA1IXYwUWhQ"
      },
      "source": [
        "Обратите внимание на следуюшие моменты:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Схожий класс использовался в лекции\n",
        "2.   Выбирайте 10 случайных сэмплов (равномерно) каждый раз.\n",
        "3.   Используйте параметры по умолчанию (epsilon=1e-6, max_steps=10000, w0=None,alpha=1e-8) \n",
        "4.   Выход из цикла осуществуется по сравнению 2-нормы разницы весов с epsilon, а функция потерь - MSE.\n",
        "\n",
        "\n",
        "\n",
        "Визуализируйте траекторию градиентного спуска (как в лекции)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmnJEKkcSB6t"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtJ1PVX2SkpV"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LinearRegressionSGD(BaseEstimator):\n",
        "    def __init__(self, epsilon=1e-6, max_steps=10000, w0=None, alpha=1e-8):\n",
        "        self.epsilon = epsilon\n",
        "        self.max_steps = max_steps\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.w_history = []"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Ow68YGSolF"
      },
      "source": [
        "def fit(self, X, y):\n",
        "        l,d = X.shape \n",
        "        if self.w0 is None:\n",
        "            self.w0 = np.zeros(d)\n",
        "        self.w = self.w0\n",
        "        for step in range(self.max_steps):\n",
        "            self.w_history.append(self.w)\n",
        "            w_new = self.w - self.alpha * self.calc_gradient(X, y)\n",
        "            if (np.linalg.norm(w_new - self.w) < self.epsilon):\n",
        "                break\n",
        "            self.w = w_new\n",
        "        return self"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olbwgz1BStVg"
      },
      "source": [
        "def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception(\"Пока не обучена\")  \n",
        "        y_pred = np.dot(X, self.w)\n",
        "        return y_pred"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3NE2dnFSywE"
      },
      "source": [
        "def calc_gradient(self, X, y):\n",
        "        l, d = X.shape\n",
        "        gradient = np.zeros((d, ))\n",
        "        indeces = np.random.randint(0, d, (10, ))\n",
        "        return (2/l) * np.dot(X.T,(np.dot(X, self.w) - y))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjywH-SuS4Ii"
      },
      "source": [
        "Визуальная часть"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cc1isS0S66I"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdOO1eBQTcK-"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}